{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alostmathematician/ISTA-366/blob/main/NB3_ISTA_322_flatten_transform_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5WKTjWAm1NB"
      },
      "source": [
        "# JSON Flattening and Transforms w/ Spotify Data\n",
        "\n",
        "This week we're going to be learning how to do transforms with JSON data.  Spotify has a wonderful API that allows access to a ton of their data.  The Spotipy package offers a nice python interface to access that.  \n",
        "\n",
        "Calls to Spotify yield info on artists/albums/songs all in JSON format.  The goal will be to get artist info along with info on the top 10 songs.  We'll then do some graphical views into the musical preferences of you all!\n",
        "\n",
        "We'll start by just working through the pipeline with a single artist.  After we learn how to wrangle data of just one artist we'll expand to a big list of artists to make our full dataset.  This takes some looping to make work so figure let's learn to deal with the JSONs first, then the loops.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjDWbXK1rgpw"
      },
      "source": [
        "## First, installing packages into Colab\n",
        "\n",
        "The spotipy package isn't preinstalled in Colab, so we gotta do that.  You can do a regular pip install:\n",
        "\n",
        "`!pip install spotipy`\n",
        "\n",
        "But the obvious issue here is that this isn't a permanent install, so if you close your notebook and come back later the install will be gone and you'll have to redo it.  Not a huge deal, but also annoying with larger packages.  \n",
        "\n",
        "What we'll do instead is mount your google drive and install the package to that.  This way whenever you come back your drive will (should) remount and you can load up the package as you normally would.\n",
        "\n",
        "**Note** You obviously don't have to do this if working locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhbgLIoYssLv"
      },
      "source": [
        "### First - Mount your drive and give access\n",
        "\n",
        "The code below brings in some utilities and then provides the paths to the notebook and where to install.  The first time you run this in a new notebook you'll have to follow the link, copy the access key and then put into the open cell and hit enter.  After you've done that once the drive should mount automatically when you reopen. *But* I've found that this can be a bit picky so post to Slack if you're having trouble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi92Ox8FbgWE"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Ykt82QtN8i"
      },
      "source": [
        "### Install library\n",
        "\n",
        "This is a regular install but you're telling it to install that into the notebook path in your drive created above.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeNRrBZgd7Cu"
      },
      "outputs": [],
      "source": [
        "# Install only once. Tomorrow, you can skip this.\n",
        "!pip install --target=$nb_path spotipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJpT-Bptnk1"
      },
      "source": [
        "## Getting Spotipy up and running\n",
        "\n",
        "Getting spotipy working is pretty easy!  Here's a step-by-step breakdown.\n",
        "\n",
        "First, just go to the Spotify Developer webpage here: https://developer.spotify.com\n",
        "\n",
        "1.   [Go to the Spotify Developer page](https://developer.spotify.com/dashboard/)\n",
        "2.   Make an account\n",
        "4.   In the Dashboard, Click 'CREATE AN APP' button in upper right\n",
        "4.   Give it a name and description (the description doesn't matter)\n",
        "5.   Click create\n",
        "6.   On the new page it'll show your Client ID and a 'Show Client Secret' line of text\n",
        "7.   Show the secret.   You'll need that and your ID for the next step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSggdPGNfIoj"
      },
      "outputs": [],
      "source": [
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "spotify_client_id = 'your_client_id'\n",
        "spotify_client_secret  = 'your_client_secret'\n",
        "\n",
        "client_credentials_manager = SpotifyClientCredentials(\n",
        "    client_id=spotify_client_id,\n",
        "    client_secret=spotify_client_secret\n",
        ")\n",
        "\n",
        "sp = spotipy.Spotify(\n",
        "    client_credentials_manager=client_credentials_manager\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaLBiihnvEr5"
      },
      "source": [
        "###  Import spotipy and inputting credentials\n",
        "\n",
        "In the cell below paste in your unique ID and secret and then run the cell.\n",
        "\n",
        "We don't alias spotipy, but we do link the credentials to an object called `sp`.  This acts as an alias to spotipy while also providing those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5D3LDpZvhZv"
      },
      "source": [
        "## Working with a single artist\n",
        "\n",
        "Let's dig in!  We're going to start with just getting info and making things work with just a single artist.  In this case we're going to get the top 10 songs and features by the artist Dance With The Dead.  \n",
        "\n",
        "You'll see that we actually need to make a range of calls to Spotify in order to build this dataset.  This is because their database is normalized where artist info is in a different database than album info, and those are different from song features...  you get the idea.  \n",
        "\n",
        "The key thing you need here is the artist URI (the unique identifier).  If you look at the image below you'll see that if you click the `...` you then then scroll to share and then copy the URI. It gives you the following \"spotify:artist:2KtnZQwMQJN3uyI8eHZRvm\"\n",
        "\n",
        "![image](https://drive.google.com/uc?export=view&id=1SKmM94qeG0DSWZTaxQ13yQUUu3tGZ-_5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypsZqbtEyJoo"
      },
      "source": [
        "### Getting artist info\n",
        "\n",
        "First thing we're going to do is call the `artist()` function on our ID and see what that gets us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VxB7jIeyYtY"
      },
      "outputs": [],
      "source": [
        "# libraries too :)\n",
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize\n",
        "\n",
        "# First, let's get an artist.  Note that you can also copy just the URI.\n",
        "art = sp.artist('spotify:artist:2KtnZQwMQJN3uyI8eHZRvm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LM1xVXU5Nja"
      },
      "outputs": [],
      "source": [
        "# Check it out\n",
        "art"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4-JalKkyrm5"
      },
      "source": [
        "### Just a little JSON\n",
        "\n",
        "Yep, so our object `art` is a JSON with a bunch of info about the band. A lot of that info is nested as well.  Let's work through it a bit.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V21dk0lyqR-"
      },
      "outputs": [],
      "source": [
        "# First, what keys are there?\n",
        "art.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezPUNbfLznxy"
      },
      "outputs": [],
      "source": [
        "# Artist name\n",
        "print(art['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9fsOzae5ft_"
      },
      "outputs": [],
      "source": [
        "# Can you get how many total followers there are?  It's two levels deep\n",
        "print(art['followers']['total'])\n",
        "\n",
        "#Question 1: What is the total number of followers of \"Dance With the Dead\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvISzRs65mQR"
      },
      "outputs": [],
      "source": [
        "# Grab the genre of music\n",
        "print(art['genres'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEmLuEx_8BXN"
      },
      "source": [
        "### Mapping that JSON to a data frame\n",
        "\n",
        "OK, so you can call up different bits from that JSON using square brackets.  But, the whole point of this is to get the data into a more useful format for analysis, which in this case means a flat structure.\n",
        "\n",
        "We're going to eventually be working with a long list of artist URIs, so we're going to make a function to extract out those elements to a list.  Then later we can use `map()` to apply that function to each element of the list.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxEMNKNK8AlQ"
      },
      "outputs": [],
      "source": [
        "# To start, you can store just a single element of that above JSON like anything else\n",
        "artist_name = art['name']\n",
        "artist_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Khy7oJ9kQe"
      },
      "source": [
        "So let's make a function to extract the name, id, number of followers, and first entry of genre.\n",
        "\n",
        "If you're rusty, remember that you define a function with the following:\n",
        "```\n",
        "def function_name(arguments):\n",
        "  action\n",
        "  action\n",
        "  return(whatever you want to have returned)\n",
        "```\n",
        "\n",
        "We're going to make a function called 'get_artist_info'.  This function will take an artist ID and then store the name, id, followers, and genre, and then add them all into a list.  The return will be that list as it'll be easy to turn into a dataframe!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3lkKJbh2SyI"
      },
      "outputs": [],
      "source": [
        "#I'll make this function for you!\n",
        "\n",
        "def get_artist_info(art_id): # define name and argument\n",
        "  art_json = sp.artist(art_id) # calling out to the spotipy function using the art_id that was given\n",
        "  artist_name = art_json['name'] # use that json object to get name\n",
        "  artist_id = art_json['id'] # artist id\n",
        "  followers = art_json['followers']['total'] #down a level in followers to get total number\n",
        "  genre = art['genres'][0] #extracting just the first genre in the list\n",
        "  art_list = [artist_name, artist_id, followers, genre] # make a list\n",
        "  return(art_list) # have your function return that list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIAWC2hQ2wXf"
      },
      "outputs": [],
      "source": [
        "# Let's call our function on the URI from Dance with the Dead (feel free to try with other artists!)\n",
        "art_list = get_artist_info('2KtnZQwMQJN3uyI8eHZRvm')\n",
        "art_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbmKgivZ36JP"
      },
      "outputs": [],
      "source": [
        "# Now we can turn that list into a dataframe using pd.DataFrame()\n",
        "# You need to provide the list and then a list of column names\n",
        "# We'll store this as 'artist_info'\n",
        "artist_info = pd.DataFrame(data = [art_list], columns = ['artist_name', 'artist_id', 'followers', 'genre'])\n",
        "artist_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClsYyONIBqYb"
      },
      "source": [
        "## Now to get the top tracks\n",
        "\n",
        "Now that we have the artist info we can get their top 10 tracks.  The function `artist_top_tracks()` returns just that if you give it an ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U9U-wJ6E_j4"
      },
      "outputs": [],
      "source": [
        "# Assign top 10 songs to artist_top\n",
        "artist_top = sp.artist_top_tracks(artist_info['artist_id'][0])\n",
        "artist_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPOolq-RClFi"
      },
      "outputs": [],
      "source": [
        "# The topmost key is 'tracks' which makes sense as it's 10 indivdiual tracks\n",
        "artist_top.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dImAiyiFC6Gr"
      },
      "outputs": [],
      "source": [
        "# Let's look at just the second track\n",
        "artist_top['tracks'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_duZ1zrCjmp"
      },
      "source": [
        "### Using pandas to normalize our JSONs\n",
        "\n",
        "So that returned a pretty large json with a lot of information.  We could go and write another function to pull out the information for each track, but instead we're going to use some of the built-in `pandas` JSON parsing functions.  \n",
        "\n",
        "`json_normalize()` will take that JSON data and turn it into a dataframe.  Let's apply it and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-xZRcrdDjVQ"
      },
      "outputs": [],
      "source": [
        "# Well this isn't helpful\n",
        "# The issue is that the data are all down a level under 'tracks'\n",
        "pd.json_normalize(artist_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuGfFM7kDt4w"
      },
      "outputs": [],
      "source": [
        "# Let's call it on artist_top['tracks']\n",
        "# Add .head(3) just to see only the first few.\n",
        "pd.json_normalize(artist_top['tracks']).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPjWQaw1EYpj"
      },
      "source": [
        "So that worked well overall!  You can see it made columns for all the levels directly under 'tracks'.  \n",
        "\n",
        "But, there's also information we want that's deeper in the JSON. For example, 'artist' has the artist name and id under it, both of which we'll need to bring our data together.  See below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvHCMHXUE0gu"
      },
      "outputs": [],
      "source": [
        "artist_top['tracks'][1]['artists']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI-vAo0LFIyW"
      },
      "source": [
        "Luckily `json_normalize()` has more functionality.  You can tell it what path you want it to  normalize with `record_path = ['level you want']`\n",
        "\n",
        "Let's try it.  Note I tossed in one more argument... `sep = '_'`. `json_normalize()` defaults to using periods as separators, but you should never use those so this'll change it to underscores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stSMD6sIFIDG"
      },
      "outputs": [],
      "source": [
        "# Try it!\n",
        "pd.json_normalize(artist_top['tracks'], record_path=['artists'], sep='_').head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nFHh9bjdUlv"
      },
      "source": [
        "Wait, that got us now our individual data about the artist, but now we lost the data about the songs themselves!\n",
        "\n",
        "Not to worry, though. You can use the meta = [] to provide a list of other information you want to attach from the json.\n",
        "\n",
        "Let's get the track id and track name. The code would look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x87zgBJRZMFU"
      },
      "outputs": [],
      "source": [
        "pd.json_normalize(artist_top['tracks'],\n",
        "                  record_path=['artists'],\n",
        "                  meta = ['id', 'name'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulunCwpGdfvh"
      },
      "source": [
        "But that throws us an error saying that there's conflicting metadata.\n",
        "\n",
        "There's an issue here that should hopefully be pretty apparent. Notice above that it also gives us the id contained in the artist section. But we obviously want the song id so we can get that info next. This'll cause a conflict as we'll then have two columns named the same. We can fix this by adding in two other arguments that tell it what prefix to give both the metadata and the record data. Given our record is asking for artist info, let's give that a prefix of 'artist_' and our meta is asking for track info we'll give that 'track_'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr9zlfz6digS"
      },
      "outputs": [],
      "source": [
        "pd.json_normalize(artist_top['tracks'],\n",
        "  record_path=['artists'],\n",
        "  meta = ['id', 'name'],\n",
        "  record_prefix = 'artist_',\n",
        "  meta_prefix = 'track_',\n",
        "  sep = '_').head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPCuu9TJWDS2"
      },
      "outputs": [],
      "source": [
        "# Lets store our data this time as top_track_info\n",
        "top_track_info = pd.json_normalize(artist_top['tracks'],\n",
        "                  record_path=['artists'],\n",
        "                  meta = ['id', 'name'],\n",
        "                  record_prefix = 'artist_',\n",
        "                  meta_prefix = 'track_',\n",
        "                  sep = '_')\n",
        "\n",
        "top_track_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iXvW_EzJsJB"
      },
      "outputs": [],
      "source": [
        "# Let's keep just the columns we need.\n",
        "# We're going to call for song specifics using track ID, but we'll also want artist ID and name for later.\n",
        "top_track_info = top_track_info[['artist_name', 'artist_id', 'track_id', 'track_name']]\n",
        "top_track_info.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJwVu4yoJ40x"
      },
      "source": [
        "OK great!  We've managed to get data from within different levels of our JSON return and wrangle that into a dataframe.  \n",
        "\n",
        "One issue though.... notice that we have places where there are duplicates of the track ID/name but two different artists.  In this case there were two artists on a single track, so we have an entry for each.  This might not be a big deal, but we're going to want to drop those and just keep the main artist.  This is because our end goal is to aggregate by artist, and don't want to run those on artists with only one song that just happened to colloborate. In other situations, we might want to keep these. As always, it depends on what the goal is/what the end user plans to do with the data.\n",
        "\n",
        "There's an easy way to deal with this.  Let's just filter our `top_track_info` dataframe to include only rows where the `artist_id` matches the `artist_name` in our `artist_info` data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yODeF3HJJoCB"
      },
      "outputs": [],
      "source": [
        "# I'm going to filter our dataframe and use the .isin() function.\n",
        "# This is asking if a level in artist_name from top_track_info is ever seen in the artist_name column in our earlier artist_info dataframe.\n",
        "print('before: ' +  ', '.join(top_track_info['artist_name'].unique())) # before\n",
        "top_track_info = top_track_info[top_track_info['artist_name'].isin(artist_info['artist_name'])]\n",
        "\n",
        "# check to verify!\n",
        "print('after: ' +  ', '.join(top_track_info['artist_name'].unique())) # after"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KVy6tBcL7SA"
      },
      "source": [
        "## Getting features of top tracks\n",
        "\n",
        "Now let's get the musical features associated with the top tracks of this artist. Spotify measures a bunch of things such as how vocal the music is (speechiness), the energy, danceability, etc. for every song.  If we want to see how musical tastes differ and graph that, we want those data!\n",
        "\n",
        "Getting these data are easy now that we have a dataframe with song ID's in it.  The function `sp.audio_features()` will take an ID and return a JSON with those values.  I'm going to let you all use that function on the track_id column, then normalize, then drop the unnecessary columns.  \n",
        "\n",
        "Note that for normalizing you don't need to do much as the JSON isn't nested.  You can call just the `json_normalize()` function.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQu6nlRoXQGt"
      },
      "outputs": [],
      "source": [
        "#get features of top tracks using audio_features\n",
        "top_track_features = sp.audio_features(top_track_info['track_id'])\n",
        "top_track_features = pd.json_normalize(top_track_features)\n",
        "top_track_features = top_track_features.drop(columns = ['uri', 'track_href', 'analysis_url', 'type'])\n",
        "top_track_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QImjV6y2MuGn"
      },
      "source": [
        "## Joining our data\n",
        "\n",
        "Major progress!  We now have three dataframes.  One has the artist info, another with top 10 songs and their IDs, and then the last that has the musical features of those top 10 songs.  How can we get those data together?  Joins!\n",
        "\n",
        "We're going to go over joins in more detail when we jump into the SQL world.  But for now, I'll give you some bullet points.\n",
        "\n",
        "*   People typically think of the dataframes they want to join as 'left' and 'right'\n",
        "*   The left can be thought of as the base and then the right is what you join to it\n",
        "*   You join based on a key.  They key is what links the left data frame to the right data frame\n",
        "*   When you do what's called a 'left join' you will attach all the info from the right data frame to its corresponding row (based on the key) to the left data frame.  \n",
        "\n",
        "\n",
        "A bit about the python function `.merge()` which you use for your dataframe.  The syntax is as follows\n",
        "```\n",
        "left_df.merge(right_df,\n",
        "  left_on = 'key in left df',\n",
        "  right_on = 'key in right',\n",
        "  how = 'type of join')\n",
        "  ```\n",
        "In this case we want to have the `top_track_info` be our left and then `top_track_features` be our right.  The key between them is the song ID, but that has a different name in each.  So for `left_on` we want to specify the column `track_id`, but in the `right_on` we use just `id` as that's what the column is called in `top_track_features`.  We want to do a left join so we use `how = 'left'`.\n",
        "\n",
        "Visually this is what the join will do:\n",
        "![image](https://drive.google.com/uc?export=view&id=10tB7qI7g9cCmDRO5FYtBxjoVvTn6zrFx)\n",
        "\n",
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4x-6jfNZcGK"
      },
      "outputs": [],
      "source": [
        "# Do a left join\n",
        "top_track_info = top_track_info.merge(top_track_features, left_on = 'track_id', right_on = 'id', how = 'left')\n",
        "top_track_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJdGBwudo2e7"
      },
      "source": [
        "Great!  So that did the trick!  You can see that the track_id and id columns have the same values.  So what `.merge()` did was take the left data frame, then grab the row from the right data frame that had the matching key and added it to the left.  \n",
        "\n",
        "This was a one to one merge in that for each row with song info there was only one row with song features.  But now let's go and add on the other artist information so this way we have the number of followers and genre.\n",
        "\n",
        "Again, a graphical depictions of what the join will do.  See how it will fill the same info in the left row for every key match:\n",
        "![image](https://drive.google.com/uc?export=view&id=1199S0cnarbs4ROVxkPkThtovCOd97eVi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQTDnvHKp6gb"
      },
      "outputs": [],
      "source": [
        "# A reminder of what's in artist_info\n",
        "artist_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCYCAjnOpbAY"
      },
      "outputs": [],
      "source": [
        "# Join artist info.  The key in this case is artist_id\n",
        "top_track_info.merge(artist_info, left_on = 'artist_id', right_on= 'artist_id', how = 'left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2fykdG8qJ9Q"
      },
      "source": [
        "Great! Looking at the far right of the dataframe you can see that it added on the number of followers and genre to every row of the dataframe.  \n",
        "\n",
        "You'll also notice as added a prefix to duplicate columns.  You could go and drop those, but we'll skip that for now.  \n",
        "\n",
        "OK, so at this point we pulled from three different datasets in JSON format and brought them together into one single data frame that could be used for visualization, analysis, or recommendations.  Of course, we want more artists in this dataset to do those things so now we're going to build this out to get information from all the artists provided on Slack!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnQHe4QJrqUl"
      },
      "source": [
        "## Making this work with lots of artists\n",
        "\n",
        "OK, so we have our process built out for a single artist.  Let's now make it work for all the artists you posted about in Slack!\n",
        "\n",
        "In general this isn't a huge deal if you remember how to leverage some of your python skills.  We'll be using two general ways of repeating a process.  Map and loops.  \n",
        "\n",
        "The `map()` function will take the function we wrote earlier and execute it across a list of values. For loops will be used as well for a similar purpose.  I'm showing you both just to get you practice!  Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NERfLX6-sKaw"
      },
      "source": [
        "### Starting with a list of artists\n",
        "\n",
        "Here's a list of the URIs for different artists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7xc6vMssTgr"
      },
      "outputs": [],
      "source": [
        "artist_list = ['1Mxqyy3pSjf8kZZL4QVxS0', '2KtnZQwMQJN3uyI8eHZRvm', '4UXqAaa6dQYAk18Lv7PEgX', '7yRimuQSC5Ks3T2Ts0iyZa', '5Ho1vKl1Uz8bJlk4vbmvmf', '7tYKF4w9nC0nq9CsPZTHyP',\n",
        "               '4q3ewBCX7sLwd24euuV69X', '6ueGR6SWhUJfvEhqkvMsVs', '3pc0bOVB5whxmD50W79wwO', '5WY88tCMFA6J6vqSN3MmDZ', '3ZjoQ5yuRyPhZSIw5nCVBb', '5DIi2JWfQPTKffaVBlIYRn',\n",
        "               '6qqNVTkY8uBg9cP3Jd7DAH', '2qxJFvFYMEDqd7ui6kSAcq', '2o5jDhtHVPhrJdv3cEQ99Z', '3EA9hVIzKfFiQI0Kikz2wo', '6nxWCVXbOlEVRexSbLsTer', '0PxzGnCYBpSuaI49OR94cA',\n",
        "               '6LuN9FCkKOj5PcnpouEgny', '3TVXtAsR1Inumwj472S9r4', '711MCceyCBcFnzjGY4Q7Un', '4gzpq5DPGxSnKTe4SA8HAU', '7oPftvlwr6VrsViSDV7fJY', '3Uobr6LgQpBbk6k4QGAb3V',\n",
        "               '4f9iBmdUOhQWeP7dcAn1pf', '0FI0kxP0BWurTz8cB8BBug', '2CIMQHirSU0MQqyYHq0eOx', '0ZMWrgLff357yxLyEU77a1', '1feoGrmmD8QmNqtK2Gdwy8', '2mVVjNmdjXZZDvhgQWiakk',\n",
        "               '57vWImR43h4CaDao012Ofp', '1uiEZYehlNivdK3iQyAbye', '6l3HvQ5sa6mXTsMTB19rO5', '4O15NlyKLIASxsJ0PrXPfz', '7F9ZL4TJNr8AoU0UUQX8ih', '49gaZqfow2v8EEQmjGyEIw'\n",
        "               ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chUbpho6sWQR"
      },
      "outputs": [],
      "source": [
        "# Here's our function again\n",
        "def get_artist_info(art_id): # define name and argument\n",
        "  art_json = sp.artist(art_id) # calling out to the spotipy function using the art_id that was given\n",
        "  artist_name = art_json['name'] # use that json object to get name\n",
        "  artist_id = art_json['id'] # artist id\n",
        "  followers = art_json['followers']['total'] #down a level in followers to get total number\n",
        "  genre = art_json['genres'][0] #extracting just the first genre in the list\n",
        "  art_list = [artist_name, artist_id, followers, genre] # make a list\n",
        "  return(art_list) # have your function return that list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfR3CFn_u83B"
      },
      "outputs": [],
      "source": [
        "# Note that it would work if we just called an element of artist_list by it's index\n",
        "get_artist_info(artist_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfTnq7fsw7Q"
      },
      "source": [
        "### Using `map()`\n",
        "\n",
        "Let's use `map()` to apply our function `get_artist_info` to every element in `artist_list`.  The syntax is:\n",
        "`map(function to apply, list to apply function to)`.\n",
        "\n",
        "So in this case, it'll grab the first id from the list, apply our function to it, store it, go to the next id, store it, and so on.\n",
        "\n",
        "Let's give it a go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ir46JXsltU"
      },
      "outputs": [],
      "source": [
        "# Apply get_artist_info function to artist_list and store as artist_info\n",
        "artist_info = map(get_artist_info, artist_list)\n",
        "artist_info #check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1O5fY6rtoy2"
      },
      "source": [
        "So it appears to have worked, but it created a map object which isn't immediately useful.  We need to tell python that we want it as a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzmfxcPStm9V"
      },
      "outputs": [],
      "source": [
        "# Apply the list() function to our map object\n",
        "artist_info = list(artist_info)\n",
        "len(artist_info) # check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD_XlA9guCn-"
      },
      "source": [
        "Great, now we have a bunch of lists each with artist info.  Now we can go and convert that into a dataframe like we did earlier in the lesson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps-jo2QNuLfq"
      },
      "outputs": [],
      "source": [
        "# Same syntax as before but this time I just told it to use different data!\n",
        "artist_info = pd.DataFrame(data = artist_info, columns= ['artist_name', 'artist_id', 'followers', 'genre'])\n",
        "artist_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-L57svlCybl"
      },
      "source": [
        "###  Getting top songs for all artists\n",
        "\n",
        "Great, so now we have a data frame with all the artists suggested by the class.  Just like before, we want to get the top 10 songs for each artist.  \n",
        "\n",
        "To do this we need to call the spotify function `sp_artist_top_tracks()` on each ID in that dataframe.  We obviously don't want to do this for every one manually, so we need to either make another function and use `map()` or we can use a for loop.  Let's use a loop so you can see how they work.  \n",
        "\n",
        "I'm going to make a short lesson on loops that you can go check out if you don't know how they work.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNOGqXUEQYZ"
      },
      "source": [
        "#### Writing our loop\n",
        "\n",
        "We know a few things about the needs for ouu loop:\n",
        "\n",
        "* We want the top track info for all artists.  This means we want the loop to run as long as the artist list is.  \n",
        "* This will return a dataframe of top songs for each artist\n",
        "* We only need the four columns we used before\n",
        "* We'll need to make an empty dataframe and append to that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LklqcNoWEuqZ"
      },
      "outputs": [],
      "source": [
        "# First, let's make an empty dataframe\n",
        "top_track_info = pd.DataFrame()\n",
        "top_track_info # Note it's empty in the return below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzWEc5lXDGTS"
      },
      "outputs": [],
      "source": [
        "# Now for our loop\n",
        "# We'll use range(len(artist_l)) so it knows to run for as long as the artists dataframe is\n",
        "for i in range(len(artist_info)):\n",
        "  art_top = sp.artist_top_tracks(artist_info['artist_id'][i]) #Call our spotipy function in the i'th element!\n",
        "  top_tracks = pd.json_normalize(art_top['tracks'], record_path=['artists'], meta = ['id', 'name'], record_prefix = 'artist_', meta_prefix = 'track_', sep = '_') # Flatten\n",
        "  top_tracks = top_tracks[['artist_name', 'artist_id', 'track_id', 'track_name']] # Select just the columns we need\n",
        "  top_track_info = top_track_info.append(top_tracks) # .append will add the top_track_info to our empty data frame and then repeatedly to the end of it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64dtfCDVGltm"
      },
      "source": [
        "That seems to have worked.  Let's check the shape, head and tail of top_tracks_info which is the dataframe that we filled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRQPhMBEF7vv"
      },
      "outputs": [],
      "source": [
        "# Check the shape...\n",
        "# More rows than we'd expect, but that makes sense if multiple artists can be tied to a single track.\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LblBh-b7G8KF"
      },
      "outputs": [],
      "source": [
        "# Head looks good.  And can see an example of another artist being linked to the same top track.\n",
        "# Not a big deal, but explains why our row count is a bit inflated\n",
        "top_track_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-iOfcC2HITJ"
      },
      "outputs": [],
      "source": [
        "# how does the tail look?\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iPSLb4EHOXT"
      },
      "source": [
        "OK, so our top tracks look good!  Let's deal with those duplicate rows as we did before.  We'll filter out rows where the artist id appeared in our original artist_info dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6sVHekEHd-x"
      },
      "outputs": [],
      "source": [
        "# Filter and check the length\n",
        "top_track_info = top_track_info[top_track_info['artist_id'].isin(artist_info['artist_id'])]\n",
        "top_track_info.shape # Great a lot shorter and where we'd expect it to be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL1NW9F3H0EQ"
      },
      "source": [
        "### Getting song features for all top songs\n",
        "\n",
        "As you can imagine, we now want to get the song features for each song in top_tracks.  \n",
        "\n",
        "\n",
        "We'll use a loop again but with one caveat...  Spotify limits the number of responses to 100.  This means we can't just go and feed it our track_id column, but instead need to loop through.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvS59xwgIovA"
      },
      "outputs": [],
      "source": [
        "top_track_features = pd.DataFrame()\n",
        "for i in range(len(top_track_info)):\n",
        "  top_track_feats = sp.audio_features(top_track_info['track_id'][i])\n",
        "  top_track_feats = pd.json_normalize(top_track_feats)\n",
        "  top_track_feats = top_track_feats.drop(columns = ['uri', 'track_href', 'analysis_url', 'type'])\n",
        "  top_track_features = top_track_features.append(top_track_feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23lyR1JdLctv"
      },
      "source": [
        "Ah, getting an error.  It's telling us it can't find a key.  So it's asking for `top_track_info['track_id'][i]` when i equals 23 (for example), and it's not there.  Why is this?  Well, remember how we were appending on dataframes to build out top_track_info dataframe?  Each time it did that it was starting the index over from 0, meaning that the index is the length of those small dataframes repeated at each iteration of the for loop, rather than starting at zero and going to the end.  So, let's reset it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAEjjdoxL-bI"
      },
      "outputs": [],
      "source": [
        "print(top_track_info.index) # Check it first\n",
        "\n",
        "# Now reset it.  Note that if you don't add drop = True it'll add the old index as a column\n",
        "top_track_info = top_track_info.reset_index(drop=True)\n",
        "\n",
        "print(top_track_info.index) # Looks better!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNhEHaZOMSwQ"
      },
      "outputs": [],
      "source": [
        "# run again!\n",
        "top_track_features = pd.DataFrame()\n",
        "for i in range(len(top_track_info)):\n",
        "  top_track_feats = sp.audio_features(top_track_info['track_id'][i])\n",
        "  top_track_feats = pd.json_normalize(top_track_feats)\n",
        "  top_track_feats = top_track_feats.drop(columns = ['uri', 'track_href', 'analysis_url', 'type'])\n",
        "  top_track_features = top_track_features.append(top_track_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cz2H_AKJoVH"
      },
      "outputs": [],
      "source": [
        "top_track_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stla1n6bM2Ea"
      },
      "source": [
        "### Joining our data\n",
        "\n",
        "Now let's join everything together just like before.  We'll do a left joint to attach the song features to our track info.  Then we'll do another to attach the artist info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpIMdo0kM7b8"
      },
      "outputs": [],
      "source": [
        "# Do a left join to join our features to our top tracks\n",
        "top_track_info = top_track_info.merge(top_track_features, left_on = 'track_id', right_on = 'id', how = 'left')\n",
        "top_track_info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNG0qJ3nnH0"
      },
      "outputs": [],
      "source": [
        "# And another to join our artist info to our top_track_info data frame\n",
        "# Join artist info.  The key in this case is the artist_id\n",
        "top_track_info = top_track_info.merge(artist_info, left_on = 'artist_id', right_on= 'artist_id', how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2-2hGM6Ni3r"
      },
      "outputs": [],
      "source": [
        "# Check!\n",
        "top_track_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRCNxjLVro96"
      },
      "source": [
        "## Plotting and Aggregating\n",
        "\n",
        "Let's take a few minutes here just to plot our data a bit and also do some aggregation.\n",
        "\n",
        "We're going to use the visualization library `seaborn`.  I think it's easier to use than matplotlib, which is perfect for this course as it's not a viz course! It's built off of matplotlib so we need to bring that in as well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcf7TJyG3V8e"
      },
      "source": [
        "First we'll make a quick scatterplot of all our songs.  We'll color the points by artist.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVcLAJ9Nse_Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plot = sns.scatterplot(data = top_track_info,\n",
        "           x = 'danceability',\n",
        "           y = 'energy',\n",
        "           hue = 'artist_name_x')\n",
        "\n",
        "plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zicoWr5k4B1I"
      },
      "source": [
        "Well, that's not ideal.  We have so many artists that we can't really distinguish the different colors. Let's sample our data to just say 6 levels and plot those.  \n",
        "\n",
        "To sample I'm randomly selecting six artists by name using `artist_info['artist_name'].sample(6)`.  I'm then filtering the `top_track_info` dataframe to include only values that are in that sample of names using `isin()`.\n",
        "\n",
        "If you run the plot repeatedly it'll generate a new sample each time.  Give it a go to see how different artists relate to one another!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eas_0PkU4ALI"
      },
      "outputs": [],
      "source": [
        "plot = sns.scatterplot(data = top_track_info[top_track_info['artist_name_x'].isin(artist_info['artist_name'].sample(6))],\n",
        "           x = 'danceability',\n",
        "           y = 'energy',\n",
        "           hue = 'artist_name_x',\n",
        "           s = 200)\n",
        "\n",
        "plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_QZlgymrhGw"
      },
      "source": [
        "## Rolling it up!\n",
        "\n",
        "We learned last lesson how to do data aggregations. It would be a good idea to do the same here as you might be more interested in the average properties of an artist vs. individual songs.  We can use a `.groupby().agg()` process like last time to group by artist name and then aggregate a bunch of the acoustic features to get their mean values for each artist.\n",
        "\n",
        "One thing to note.  `groupby()` will automatically set whatever grouping level you use as the index.  This would be fine and you could graph with that. But, I'd rather just keep the artist_name column as an actual column and not as an index.  This  means inside `groupby()` you just add an additional argument `groupby(['artist_name_x'], as_index = False)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFwU0cGUrZSl"
      },
      "outputs": [],
      "source": [
        "songs_agg = top_track_info.groupby(['artist_name_x'], as_index = False).agg({'danceability': ['mean'],\n",
        "                                                                        'energy': ['mean'],\n",
        "                                                                        'loudness': ['mean'],\n",
        "                                                                        'speechiness': ['mean'],\n",
        "                                                                        'acousticness': ['mean'],\n",
        "                                                                        'tempo': ['mean']})\n",
        "songs_agg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N4uwmaG8O1i"
      },
      "source": [
        "Cool!  Let's take a minute to rename those columns. We'll also join back on some of the general info about the artists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq44RHf-8Rvn"
      },
      "outputs": [],
      "source": [
        "# Rename like last time\n",
        "songs_agg.columns = ['artist_name', 'mean_dance', 'mean_energy', 'mean_loud', 'mean_speech', 'mean_acoustic', 'mean_tempo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVwafaTM8dJQ"
      },
      "outputs": [],
      "source": [
        "# Now join on our artist_info\n",
        "# A reminder of what that looks like\n",
        "artist_info.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAlF4edG8lH4"
      },
      "outputs": [],
      "source": [
        "# Do our join\n",
        "songs_agg = songs_agg.merge(artist_info, left_on='artist_name', right_on='artist_name', how = 'left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KphvDd1D8ogD"
      },
      "source": [
        "Now we can ask some general question such as what artist has the most energy, or is the most danceable for example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3u1tXh8-iW3"
      },
      "outputs": [],
      "source": [
        "# Most danceable?\n",
        "songs_agg[songs_agg['mean_dance'] == songs_agg['mean_dance'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlc1kZKm-vOk"
      },
      "outputs": [],
      "source": [
        "# Most energy?\n",
        "songs_agg[songs_agg['mean_energy'] == songs_agg['mean_energy'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53yZ0oos7Ua3"
      },
      "outputs": [],
      "source": [
        "# Can you figure out which one has the lowest energy?\n",
        "# Most acoustic?\n",
        "...\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK6nhVKf8wfc"
      },
      "source": [
        "Let's make a scatterplot using this aggregated data!\n",
        "\n",
        "Unfortunately matplotlib, which seaborn runs off of, limits the number of unique points to 6. It makes sense as narrowly different points can be hard to distinguish (e.g. a hexagon vs. pentagon).  Still, we can make a workaround by making a list using unique marker types and then telling our plot to use these vs. the default six.  There are a total of 17 unique markers in all.\n",
        "\n",
        "I'll sample the data like before, but this time to the length of the list of markers.  This way if you want to shorten you can."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1npL0jSlx9cQ"
      },
      "outputs": [],
      "source": [
        "filled_markers = ('o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X', '.', ',')\n",
        "len(filled_markers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw2B2vKfv7cN"
      },
      "outputs": [],
      "source": [
        "# Give it a go!\n",
        "plot = sns.scatterplot(data = songs_agg[songs_agg['artist_name'].isin(songs_agg['artist_name'].sample(len(filled_markers)))],\n",
        "                       x = 'mean_dance',\n",
        "                       y = 'mean_energy',\n",
        "                       hue = 'artist_name',\n",
        "                       style = 'artist_name',\n",
        "                       markers=filled_markers,\n",
        "                       s = 400)\n",
        "plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
        "plt.show()\n",
        "\n",
        "#Question 2) save the picture and submit and upload it the quiz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpJPdV4t1EzN"
      },
      "source": [
        "## Wrapping up!\n",
        "\n",
        "In this lesson we made a dataset that flattened a bunch of JSON responses and brought them together into a single dataset that could be used for a variety of purposes.  For one, you could do some cluster analysis to determine which artists are similar in terms of their musical properties.  You could also make a classification system where you take these properties and use them to automatically label the genre of music.  Finally, you could use this to recommend new music to someone.  If you find they're listening to music with certain tempo, loudness, and energy values you could recommend songs or artists (based on their grouped values) with similar metrics.  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
